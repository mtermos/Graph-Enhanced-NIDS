{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-24T12:01:21.407444Z","iopub.status.busy":"2024-08-24T12:01:21.407010Z","iopub.status.idle":"2024-08-24T12:01:29.827271Z","shell.execute_reply":"2024-08-24T12:01:29.826059Z","shell.execute_reply.started":"2024-08-24T12:01:21.407404Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import pickle\n","import time\n","import timeit\n","import json\n","\n","os.environ[\"DGLBACKEND\"] = \"pytorch\"\n","\n","from dgl import from_networkx\n","import networkx as nx\n","\n","\n","import torch as th\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report\n","from sklearn.utils import class_weight\n","\n","import matplotlib.pyplot as plt\n","import itertools\n","\n","from src.graph_neural_networks import GRAPHSAGE, GAT, GCN\n","from src.dataset.dataset_info import datasets\n","from src.graph.graph_measures import calculate_graph_measures\n","\n","# datasets = {dataset.name: dataset for dataset in datasets_list}\n","\n","num_epochs = 100\n","batch_size = 128\n","learning_rate = 0.001\n","LAMBD_1 = 0.0001\n","LAMBD_2 = 0.001\n","\n","\n","gcn = False\n","graph_sage = True\n","gat = False\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["name = \"cic_ids_2017_5_percent\"\n","# name = \"cic_ton_iot_5_percent\"\n","# name = \"cic_ton_iot\"\n","# name = \"cic_ids_2017\"\n","# name = \"nf_bot_iot\"\n","# name = \"edge_iiot\"\n","# name = \"nf_cse_cic_ids2018\"\n","# name = \"nf_bot_iotv2\"\n","# name = \"nf_uq_nids\"\n","# name = \"x_iiot\"\n","# name = \"cic_ton_iot_modified\"\n","# name = \"nf_ton_iotv2_modified\"\n","# name = \"ccd_inid_modified\"\n","# name = \"nf_uq_nids_modified\"\n","\n","dataset = datasets[name]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_final = {}\n","\n","results_final[\"name\"] = name\n","results_final[\"configuration\"] = {\n","    \"num_epochs\": num_epochs,\n","    \"batch_size\": batch_size,\n","    # \"early_stopping\": early_stopping,\n","    # \"pca\": pca,\n","    # \"digraph_centralities\": digraph_centralities,\n","    # \"multi_graph_centralities\": multi_graph_centralities,\n","    # \"learning_rate\": learning_rate,\n","    # \"LAMBD_1\": LAMBD_1,\n","    # \"LAMBD_2\": LAMBD_2,\n","    # \"cfg\": OmegaConf.to_container(cfg)\n","}\n","\n","results_final[\"accuracy\"] = {}\n","\n","if gcn:\n","    results_final[\"gcn\"] = {}\n","\n","if graph_sage:\n","    results_final[\"graph_sage\"] = {}\n","\n","if gat:\n","    results_final[\"gat\"] = {}\n","\n","results_final"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dtime = time.strftime(\"%Y%m%d-%H%M%S\")\n","dtime"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_folder_path = \"results\"\n","results_folder_path1 = os.path.join(results_folder_path, name)\n","results_folder_path2 = os.path.join(results_folder_path1, \"line_graph_unsorted\")\n","folder_path = os.path.join(results_folder_path2, dtime)\n","confusion_matrices_path = os.path.join(folder_path, \"confusion_matrices\")\n","os.makedirs(confusion_matrices_path, exist_ok=True)\n","# os.makedirs(confusion_matrices_path, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_folder_path = None\n","dataset_folder_path_train = None\n","dataset_folder_path_test = None\n","\n","dataset_folder_path = os.path.join(\"datasets\", name, \"line_graph_sorted\", \"graphs\")\n","# dataset_folder_path = os.path.join(\"datasets\", name, \"line_graph_unsorted\", \"graphs\")\n","\n","# dataset_folder_path_train = os.path.join(\"datasets\", name, \"line_graph_sorted_train_test\", \"training\")\n","# dataset_folder_path_test = os.path.join(\"datasets\", name, \"line_graph_sorted_train_test\", \"testing\")\n","\n","# dataset_folder_path_train = os.path.join(\"datasets\", name, \"line_graph_unsorted_train_test\", \"training\")\n","# dataset_folder_path_test = os.path.join(\"datasets\", name, \"line_graph_unsorted_train_test\", \"testing\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# read training and testing graphs\n","if dataset_folder_path:\n","    graphs = []\n","    for file in os.listdir(dataset_folder_path):\n","        # print(f\"==>> file: {os.path.join(dataset_folder_path_train, file)}\")\n","        with open(os.path.join(dataset_folder_path, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            # print(list(G.nodes(data=True))[0])\n","            G = from_networkx(G,node_attrs=['h',dataset.label_col, \"index\"])\n","            node_label = G.ndata[dataset.label_col]\n","            # if len(node_label.unique()) > 1:\n","            #     print(f\"==>> node_label.unique(): {len(node_label.unique())}\")\n","                \n","            graphs.append(G)\n","\n","            # break\n","            \n","    training_graphs, testing_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n","    len(training_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dataset_folder_path_train:\n","    training_graphs = []\n","    for file in os.listdir(dataset_folder_path_train):\n","        # print(f\"==>> file: {os.path.join(dataset_folder_path_train, file)}\")\n","        with open(os.path.join(dataset_folder_path_train, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            # print(list(G.nodes(data=True))[0])\n","            G = from_networkx(G,node_attrs=['h',dataset.label_col, \"index\"])\n","            node_label = G.ndata[dataset.label_col]\n","            # if len(node_label.unique()) > 1:\n","            #     print(f\"==>> node_label.unique(): {len(node_label.unique())}\")\n","                \n","            training_graphs.append(G)\n","\n","            # break\n","            \n","    len(training_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compute_accuracy(pred, labels):\n","    return (pred.round() == labels).float().mean().item()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["G0 = training_graphs[0]\n","features_number = G.ndata['h'].shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_gnn(model, graphs):\n","        \n","    opt = th.optim.Adam(model.parameters())\n","    criterion = nn.BCELoss()\n","    # criterion = nn.CrossEntropyLoss()\n","\n","    for epoch in range(1,num_epochs):\n","        predictions = []\n","        labels = []\n","        for G in graphs:\n","            # class_weights = class_weight.compute_class_weight('balanced',\n","            #                                          classes = np.unique(node_label.cpu().numpy()),\n","            #                                          y = node_label.cpu().numpy())\n","            # class_weights = th.FloatTensor(class_weights)\n","            # criterion = nn.CrossEntropyLoss(weight = class_weights)\n","            # criterion = nn.BCELoss(weight = class_weights)\n","            \n","            node_features = G.ndata['h']\n","            node_label = G.ndata[dataset.label_col].float()\n","            # print(f\"==>> node_label.unique(): {node_label.unique()}\")\n","            # node_index = G.ndata[\"index\"]\n","            \n","            #     pred = model(G, node_features,edge_features).cuda()\n","            pred = model(G, node_features).squeeze(1)\n","            predictions.append(pred)\n","            labels.append(node_label)\n","            loss = criterion(pred, node_label)\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            \n","        predictions_tensor = th.cat(predictions, dim=0)\n","        labels_tensor = th.cat(labels, dim=0)\n","\n","        # print('Training acc:', compute_accuracy(pred, node_label))\n","        print('Epoch:', epoch ,' Training acc:', compute_accuracy(predictions_tensor, labels_tensor))\n","    return model\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training EGCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gcn:\n","    model = GCN(features_number)\n","    model_gcn = train_gnn(model, training_graphs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training EGraphSage "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if graph_sage:\n","    # (``mean``, ``gcn``, ``pool``, ``lstm``)\n","    model = GRAPHSAGE(features_number, aggregator_type = \"gcn\")\n","    # model = GRAPHSAGE(features_number, aggregator_type = \"lstm\")\n","    model_sage = train_gnn(model, training_graphs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Training EGAT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gat:\n","    model = GAT(features_number)\n","    model_gat = train_gnn(model, training_graphs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dataset_folder_path_test:\n","    testing_graphs = []\n","    for file in os.listdir(dataset_folder_path_test):\n","        # print(f\"==>> file: {os.path.join(dataset_folder_path_test, file)}\")\n","        with open(os.path.join(dataset_folder_path_test, file), \"rb\") as f:\n","            G = pickle.load(f)\n","            # print(list(G.nodes(data=True))[0])\n","            G = from_networkx(G,node_attrs=['h',dataset.label_col, \"index\"])\n","            node_label = G.ndata[dataset.label_col]\n","            # if len(node_label.unique()) > 1:\n","            #     print(f\"==>> node_label.unique(): {len(node_label.unique())}\")\n","                \n","            testing_graphs.append(G)\n","\n","            # break\n","            \n","    len(testing_graphs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_gnn(model, graphs):\n","    predictions = []\n","    labels = []\n","    start_time = timeit.default_timer()\n","    for G in graphs:\n","        \n","        node_features_test  = G.ndata['h']\n","        node_label_test  = G.ndata[dataset.label_col].float()\n","        test_pred = model(G, node_features_test).squeeze(1)\n","        predictions.append(test_pred)\n","        # print(f\"==>> predictions: {predictions}\")\n","        labels.append(node_label_test)\n","        # print(f\"==>> labels: {labels}\")\n","    \n","    elapsed = timeit.default_timer() - start_time\n","    print(str(elapsed) + ' seconds')\n","\n","    predictions_tensor = th.cat(predictions, dim=0).round().detach().numpy()\n","    print(f\"==>> predictions_tensor: {predictions_tensor}\")\n","    labels_tensor = th.cat(labels, dim=0)\n","    print(f\"==>> labels_tensor: {labels_tensor}\")\n","\n","    return (labels_tensor, predictions_tensor)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def calculate_FPR_FNR(cm):\n"," \n","    TN = cm[0][0]\n","    FN = cm[1][0]\n","    TP = cm[1][1]\n","    FP = cm[0][1]\n"," \n","    # Sensitivity, hit rate, recall, or true positive rate\n","    TPR = TP/(TP+FN)\n","    # Specificity or true negative rate\n","    TNR = TN/(TN+FP)\n","    # Precision or positive predictive value\n","    PPV = TP/(TP+FP)\n","    # Negative predictive value\n","    NPV = TN/(TN+FN)\n","    # Fall out or false positive rate\n","    FPR = FP/(FP+TN)\n","    # False negative rate\n","    FNR = FN/(TP+FN)\n","    # False discovery rate\n","    FDR = FP/(TP+FP)\n"," \n","    return FPR, FNR"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True,\n","                          file_path = None):\n","    \n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(12, 12))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","    if file_path:\n","        plt.savefig(file_path)\n","    plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Testing EGCN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gcn:\n","    actual, test_pred = test_gnn(model_gcn, testing_graphs)\n","\n","    actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual]\n","    test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gcn:\n","    labels = [\"Normal\", \"Attack\"]\n","    cm = confusion_matrix(actual, test_pred, labels= labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gcn:\n","    plot_confusion_matrix(cm = cm,\n","                      normalize    = False,\n","                      target_names = labels,\n","                      title        = \"Confusion Matrix\",\n","                      file_path = confusion_matrices_path + '/gcn.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gcn:\n","    FPR, FNR = calculate_FPR_FNR(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gcn:\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True)\n","    results_final[\"gcn\"][\"classification_report\"] = cr\n","    results_final[\"gcn\"][\"FPR\"] = FPR\n","    results_final[\"gcn\"][\"FNR\"] = FNR\n","    results_final[\"accuracy\"][\"gcn\"] = cr[\"accuracy\"]\n","\n","    print(classification_report(actual, test_pred, digits=4))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Testing EGraphSage"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if graph_sage:\n","    actual, test_pred = test_gnn(model_sage, testing_graphs)\n","\n","    actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual]\n","    test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if graph_sage:\n","    labels = [\"Normal\", \"Attack\"]\n","    cm = confusion_matrix(actual, test_pred, labels= labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if graph_sage:\n","    plot_confusion_matrix(cm = cm,\n","                      normalize    = False,\n","                      target_names = labels,\n","                      title        = \"Confusion Matrix\",\n","                      file_path = confusion_matrices_path + '/e_graph_sage.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if graph_sage:\n","    FPR, FNR = calculate_FPR_FNR(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if graph_sage:\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True)\n","    results_final[\"graph_sage\"][\"classification_report\"] = cr\n","    results_final[\"graph_sage\"][\"FPR\"] = FPR\n","    results_final[\"graph_sage\"][\"FNR\"] = FNR\n","    results_final[\"accuracy\"][\"graph_sage\"] = cr[\"accuracy\"]\n","\n","    print(classification_report(actual, test_pred, digits=4))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Testing EGAT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gat:\n","    actual, test_pred = test_gnn(model_gat, testing_graphs)\n","\n","    actual = [\"Normal\" if i == 0 else \"Attack\" for i in actual]\n","    test_pred = [\"Normal\" if i == 0 else \"Attack\" for i in test_pred]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gat:\n","    labels = [\"Normal\", \"Attack\"]\n","    cm = confusion_matrix(actual, test_pred, labels= labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gat:\n","    plot_confusion_matrix(cm = cm,\n","                      normalize    = False,\n","                      target_names = labels,\n","                      title        = \"Confusion Matrix\",\n","                      file_path = confusion_matrices_path + '/e_gat.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gat:\n","    FPR, FNR = calculate_FPR_FNR(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if gat:\n","    cr = classification_report(actual, test_pred, digits=4, output_dict=True)\n","    results_final[\"gat\"][\"classification_report\"] = cr\n","    results_final[\"gat\"][\"FPR\"] = FPR\n","    results_final[\"gat\"][\"FNR\"] = FNR\n","    results_final[\"accuracy\"][\"gat\"] = cr[\"accuracy\"]\n","\n","    print(classification_report(actual, test_pred, digits=4))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Saving results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NumpyEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        elif isinstance(obj, np.floating):\n","            return float(obj)\n","        elif isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        return super(NumpyEncoder, self).default(obj)\n","\n","filename = (folder_path + '/results.json'.format(dtime))\n","outfile = open(filename, 'w')\n","outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n","outfile.close()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4775518,"sourceId":8089266,"sourceType":"datasetVersion"},{"datasetId":4775527,"sourceId":8089281,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
