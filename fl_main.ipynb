{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_class: false\n",
      "with_network_features: false\n",
      "n_clients: 5\n",
      "n_rounds: 20\n",
      "config_fit:\n",
      "  momentum: 0.9\n",
      "  local_epochs: 3\n",
      "  batch_size: 256\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20241101-232918'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "from math import floor\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "\n",
    "from logging import INFO, DEBUG\n",
    "from flwr.common.logger import log\n",
    "\n",
    "from keras import layers, models, Input, regularizers, optimizers\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "from src.deep_learning.evaluation_metrics import custom_acc_mc, custom_acc_binary\n",
    "from src.dataset.dataset_info import datasets\n",
    "from src.federated_learning.read_clients import read_clients\n",
    "\n",
    "with initialize(version_base=None, config_path=\"conf/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "    print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "\n",
    "dataset = datasets[\"cic_ton_iot_5_percent\"]\n",
    "\n",
    "folder_path = \"./datasets/gdlc/\"\n",
    "# folder_path = \"./datasets/dbp/\"\n",
    "\n",
    "lr_decay = True\n",
    "early_stopping = False\n",
    "\n",
    "pca = True\n",
    "digraph_centralities = True\n",
    "multi_graph_centralities = False\n",
    "\n",
    "learning_rate = 0.0001\n",
    "LAMBD_1 = 0.0001\n",
    "LAMBD_2 = 0.001\n",
    "\n",
    "dtime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "dtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_paths = [\n",
    "    folder_path + \"client_0.parquet\",\n",
    "    folder_path + \"client_1.parquet\",\n",
    "    folder_path + \"client_2.parquet\",\n",
    "    folder_path + \"client_3.parquet\",\n",
    "    folder_path + \"client_4.parquet\",\n",
    "    folder_path + \"client_5.parquet\",\n",
    "    folder_path + \"client_6.parquet\",\n",
    "    folder_path + \"client_7.parquet\"\n",
    "    # folder_path + \"test.parquet\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_global_betweenness',\n",
       "   'dst_global_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_global_degree',\n",
       "   'dst_global_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_global_pagerank',\n",
       "   'dst_global_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_mv',\n",
       "   'dst_mv'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_global_betweenness',\n",
       "   'dst_global_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_global_degree',\n",
       "   'dst_global_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_global_pagerank',\n",
       "   'dst_global_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_mv',\n",
       "   'dst_mv']],\n",
       " ['global_pca_1',\n",
       "  'global_pca_2',\n",
       "  'global_pca_3',\n",
       "  'global_pca_4',\n",
       "  'global_pca_5',\n",
       "  'global_pca_6',\n",
       "  'global_pca_7'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(folder_path + \"added_columns.pkl\", 'rb') as f:\n",
    "    centralities_columns, pca_columns = pickle.load(f)\n",
    "centralities_columns, pca_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> classes_set: {'benign', 'attack'}\n",
      "==>> num_classes: 2\n",
      "==>> labels_names: {0: 'benign', 1: 'attack'}\n"
     ]
    }
   ],
   "source": [
    "# the input dimension of the training set\n",
    "# input_dim = df.shape[1] - len(drop_columns) - len(weak_columns) - 1  # for the label_column\n",
    "  \n",
    "# specifying the number of classes, since it is different from one dataset to another and also if binary or multi-class classification\n",
    "classes_set = {\"benign\", \"attack\"}\n",
    "labels_names = {0: \"benign\", 1: \"attack\"}\n",
    "num_classes = 2\n",
    "if cfg.multi_class:\n",
    "    with open(folder_path + \"labels_names.pkl\", 'rb') as f:\n",
    "        labels_names, classes_set = pickle.load(f)\n",
    "    num_classes = len(classes_set)\n",
    "    \n",
    "labels_names = {int(k): v for k, v in labels_names.items()}\n",
    "\n",
    "print(f\"==>> classes_set: {classes_set}\")\n",
    "print(f\"==>> num_classes: {num_classes}\")\n",
    "print(f\"==>> labels_names: {labels_names}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(input_shape, alpha = learning_rate):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv1D(80, kernel_size=3,\n",
    "                activation=\"relu\", input_shape=(input_shape, 1), kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # .L1L2(l1=LAMBD_1, l2=LAMBD_2)\n",
    "    model.add(layers.Conv1D(80, 3, activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.MaxPooling1D())\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # model.add(layers.LSTM(units=80,\n",
    "    #                         activation='relu',\n",
    "    #                         kernel_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2),\n",
    "    #                         recurrent_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2),\n",
    "    #                         bias_regularizer=regularizers.L1L2(l1=LAMBD_1, l2=LAMBD_2),\n",
    "    #                         return_sequences=False,\n",
    "    #                         ))\n",
    "    # model.add(layers.LayerNormalization(axis=1))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(200,activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(200,activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(80,activation='relu', kernel_regularizer=regularizers.L2(l2=LAMBD_2)))\n",
    "    model.add(layers.LayerNormalization(axis=1))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "\n",
    "    if cfg.multi_class:\n",
    "        model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=alpha),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    else:\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=alpha),\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1440</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">288,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │            \u001b[38;5;34m78\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │        \u001b[38;5;34m19,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │            \u001b[38;5;34m36\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m80\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1440\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m288,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m40,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │        \u001b[38;5;34m16,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m81\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">365,235</span> (1.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m365,235\u001b[0m (1.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">365,235</span> (1.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m365,235\u001b[0m (1.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_keras_model(80)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': '{\"module\": \"keras\", \"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"trainable\": true, \"dtype\": \"float32\", \"layers\": [{\"module\": \"keras.layers\", \"class_name\": \"InputLayer\", \"config\": {\"batch_shape\": [null, 80, 1], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"input_layer\"}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 80, \"kernel_size\": [3], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.001}, \"registered_name\": null}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 80, 1]}}, {\"module\": \"keras.layers\", \"class_name\": \"MaxPooling1D\", \"config\": {\"name\": \"max_pooling1d\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2], \"padding\": \"valid\", \"strides\": [2], \"data_format\": \"channels_last\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 78, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"layer_normalization\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 39, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.3, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Conv1D\", \"config\": {\"name\": \"conv1d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 80, \"kernel_size\": [3], \"strides\": [1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.001}, \"registered_name\": null}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 39, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"MaxPooling1D\", \"config\": {\"name\": \"max_pooling1d_1\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2], \"padding\": \"valid\", \"strides\": [2], \"data_format\": \"channels_last\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 37, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"layer_normalization_1\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 18, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.3, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 18, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 200, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.001}, \"registered_name\": null}, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 1440]}}, {\"module\": \"keras.layers\", \"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"layer_normalization_2\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 200]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_2\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.1, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 200, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.001}, \"registered_name\": null}, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 200]}}, {\"module\": \"keras.layers\", \"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"layer_normalization_3\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 200]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_3\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.1, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 80, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.001}, \"registered_name\": null}, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 200]}}, {\"module\": \"keras.layers\", \"class_name\": \"LayerNormalization\", \"config\": {\"name\": \"layer_normalization_4\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 80]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_4\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.1, \"seed\": null, \"noise_shape\": null}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 80]}}], \"build_input_shape\": [null, 80, 1]}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 80, 1]}, \"compile_config\": {\"optimizer\": {\"module\": \"keras.optimizers\", \"class_name\": \"Adam\", \"config\": {\"name\": \"adam\", \"learning_rate\": 9.999999747378752e-05, \"weight_decay\": null, \"clipnorm\": null, \"global_clipnorm\": null, \"clipvalue\": null, \"use_ema\": false, \"ema_momentum\": 0.99, \"ema_overwrite_frequency\": null, \"loss_scale_factor\": null, \"gradient_accumulation_steps\": null, \"beta_1\": 0.9, \"beta_2\": 0.999, \"epsilon\": 1e-07, \"amsgrad\": false}, \"registered_name\": null}, \"loss\": \"binary_crossentropy\", \"loss_weights\": null, \"metrics\": [\"accuracy\"], \"weighted_metrics\": null, \"run_eagerly\": false, \"steps_per_execution\": 1, \"jit_compile\": false}}',\n",
       " 'configuration': {'folder_path': './datasets/gdlc/',\n",
       "  'lr_decay': True,\n",
       "  'early_stopping': False,\n",
       "  'pca': True,\n",
       "  'digraph_centralities': True,\n",
       "  'multi_graph_centralities': False,\n",
       "  'learning_rate': 0.0001,\n",
       "  'LAMBD_1': 0.0001,\n",
       "  'LAMBD_2': 0.001,\n",
       "  'cfg': {'multi_class': False,\n",
       "   'with_network_features': False,\n",
       "   'n_clients': 5,\n",
       "   'n_rounds': 20,\n",
       "   'config_fit': {'momentum': 0.9, 'local_epochs': 3, 'batch_size': 256}}},\n",
       " 'pca_columns': ['global_pca_1',\n",
       "  'global_pca_2',\n",
       "  'global_pca_3',\n",
       "  'global_pca_4',\n",
       "  'global_pca_5',\n",
       "  'global_pca_6',\n",
       "  'global_pca_7'],\n",
       " 'centralities_columns': [['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_global_betweenness',\n",
       "   'dst_global_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_global_degree',\n",
       "   'dst_global_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_global_pagerank',\n",
       "   'dst_global_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_mv',\n",
       "   'dst_mv'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_local_betweenness',\n",
       "   'dst_local_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_local_degree',\n",
       "   'dst_local_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_local_pagerank',\n",
       "   'dst_local_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_Comm',\n",
       "   'dst_Comm'],\n",
       "  ['src_betweenness',\n",
       "   'dst_betweenness',\n",
       "   'src_global_betweenness',\n",
       "   'dst_global_betweenness',\n",
       "   'src_degree',\n",
       "   'dst_degree',\n",
       "   'src_global_degree',\n",
       "   'dst_global_degree',\n",
       "   'src_eigenvector',\n",
       "   'dst_eigenvector',\n",
       "   'src_closeness',\n",
       "   'dst_closeness',\n",
       "   'src_pagerank',\n",
       "   'dst_pagerank',\n",
       "   'src_global_pagerank',\n",
       "   'dst_global_pagerank',\n",
       "   'src_k_core',\n",
       "   'dst_k_core',\n",
       "   'src_k_truss',\n",
       "   'dst_k_truss',\n",
       "   'src_mv',\n",
       "   'dst_mv']],\n",
       " 'baseline': {'accuracy': {}, 'f1s': {}},\n",
       " 'PCA': {'accuracy': {}, 'f1s': {}},\n",
       " 'digraph': {'accuracy': {}, 'f1s': {}},\n",
       " 'multidigraph': {'accuracy': {}, 'f1s': {}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_final = {}\n",
    "\n",
    "results_final[\"model\"] = model.to_json()\n",
    "# results_final[\"model\"] = {}\n",
    "results_final[\"configuration\"] = {\n",
    "    \"folder_path\": folder_path,\n",
    "    \"lr_decay\": lr_decay,\n",
    "    \"early_stopping\": early_stopping,\n",
    "    \"pca\": pca,\n",
    "    \"digraph_centralities\": digraph_centralities,\n",
    "    \"multi_graph_centralities\": multi_graph_centralities,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"LAMBD_1\": LAMBD_1,\n",
    "    \"LAMBD_2\": LAMBD_2,\n",
    "    \"cfg\": OmegaConf.to_container(cfg)\n",
    "}\n",
    "\n",
    "if pca:\n",
    "    results_final[\"pca_columns\"] = pca_columns\n",
    "if digraph_centralities:\n",
    "    results_final[\"centralities_columns\"] = centralities_columns\n",
    "    \n",
    "results_final[\"baseline\"] = {}\n",
    "results_final[\"baseline\"][\"accuracy\"] = {}\n",
    "results_final[\"baseline\"][\"f1s\"] = {}\n",
    "\n",
    "results_final[\"PCA\"] = {}\n",
    "results_final[\"PCA\"][\"accuracy\"] = {}\n",
    "results_final[\"PCA\"][\"f1s\"] = {}\n",
    "\n",
    "results_final[\"digraph\"] = {}\n",
    "results_final[\"digraph\"][\"accuracy\"] = {}\n",
    "results_final[\"digraph\"][\"f1s\"] = {}\n",
    "\n",
    "results_final[\"multidigraph\"] = {}\n",
    "results_final[\"multidigraph\"][\"accuracy\"] = {}\n",
    "results_final[\"multidigraph\"][\"f1s\"] = {}\n",
    "\n",
    "results_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, logdir, x_train, y_train, x_val, y_val, x_test, y_test, input_dim):\n",
    "        self.logdir = logdir\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_val, self.y_val = x_val, y_val  \n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "        self.input_dim = input_dim\n",
    "        self.model = create_keras_model(input_shape=input_dim)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def set_parameters(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \n",
    "        lr=float(config[\"lr\"])\n",
    "        self.model = create_keras_model(input_shape=self.input_dim, alpha=lr)\n",
    "        self.set_parameters(parameters, config)\n",
    "\n",
    "        tensorboard_callback = TensorBoard(log_dir=self.logdir)\n",
    "        callbacks=[tensorboard_callback]\n",
    "        if early_stopping:\n",
    "            early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "            callbacks.append(early_stopping_callback)\n",
    "\n",
    "        history = self.model.fit(self.x_train, self.y_train,\n",
    "                                epochs=config[\"local_epochs\"],\n",
    "                                batch_size=config[\"batch_size\"],\n",
    "                                validation_data=(self.x_val, self.y_val),  \n",
    "                                verbose=0,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        return self.get_parameters(config), len(self.x_train), {k: v[-1] for k, v in history.history.items()}\n",
    "\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters, config)\n",
    "        loss, accuracy = self.model.evaluate(self.x_test, self.y_test, cfg.config_fit.batch_size, verbose=0)\n",
    "        return loss, len(self.x_test), {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn(data, simulation_name, input_dim):\n",
    "    def client_fn(cid: str):\n",
    "        i = int(cid)\n",
    "        logdir = \"logs/scalars/{}/{}/client_{}\".format(dtime, simulation_name, cid)\n",
    "        return FLClient(\n",
    "            logdir,\n",
    "            data[i][0],  # x_train\n",
    "            data[i][1],  # y_train\n",
    "            data[i][2],  # x_val\n",
    "            data[i][3],  # y_val\n",
    "            data[i][4],  # x_test\n",
    "            data[i][5],   # y_test\n",
    "            input_dim\n",
    "        ).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_fit_config(config: DictConfig):\n",
    "\n",
    "    def fit_config_fn(server_round: int):\n",
    "        alpha = learning_rate\n",
    "        if lr_decay and server_round > 5:\n",
    "            alpha = alpha / (1 + 0.5 * server_round)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"lr\": alpha,\n",
    "            \"local_epochs\": config.local_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "        }\n",
    "\n",
    "    return fit_config_fn\n",
    "\n",
    "\n",
    "def get_evaluate_fn(x_test_sever, y_test_server, input_dim, simulation_name, results, test_by_class):\n",
    "\n",
    "    def evaluate_fn(server_round: int, parameters, config):\n",
    "        # eval_model = model\n",
    "        eval_model = create_keras_model(input_shape=input_dim)\n",
    "        eval_model.set_weights(parameters)\n",
    "\n",
    "        \n",
    "        logdir = \"logs/scalars/{}/{}/server\".format(dtime, simulation_name) \n",
    "        # logdir = \"logs/scalars/client{}_\".format(config[\"cid\"]) + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "        test_loss, test_acc = eval_model.evaluate(x_test_sever, y_test_server,\n",
    "                                                  batch_size = cfg.config_fit.batch_size,\n",
    "                                                  callbacks=[tensorboard_callback])\n",
    "        \n",
    "        \n",
    "        y_pred = eval_model.predict(x_test_sever, batch_size = cfg.config_fit.batch_size)\n",
    "        \n",
    "        if cfg.multi_class:\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            scores = custom_acc_mc(y_test_server, y_pred)\n",
    "        else:\n",
    "            y_pred = np.transpose(y_pred)[0]\n",
    "            y_pred = list(\n",
    "                map(lambda x: 0 if x < 0.5 else 1, y_pred))\n",
    "            scores = custom_acc_binary(y_test_server, y_pred)\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        \n",
    "        results[\"scores\"][\"accuracy\"][server_round] = test_acc\n",
    "        results[\"scores\"][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        results[\"scores\"][\"server\"][server_round] = scores\n",
    "        \n",
    "        results_final[simulation_name][\"accuracy\"][server_round] = scores[\"accuracy\"]\n",
    "        results_final[simulation_name][\"f1s\"][server_round] = scores[\"f1s\"]\n",
    "        \n",
    "        if not cfg.multi_class:\n",
    "            for k in test_by_class.keys():\n",
    "                y_pred_class = eval_model.predict(test_by_class[k][0], batch_size = cfg.config_fit.batch_size, verbose = 0)\n",
    "                y_pred_class = np.transpose(y_pred_class)[0]\n",
    "                y_pred_class = list(map(lambda x: 0 if x < 0.5 else 1, y_pred_class))\n",
    "                scores_class = custom_acc_binary(test_by_class[k][1], y_pred_class)\n",
    "                results[\"scores\"][\"test_by_class\"][\"accuracy\"][k][server_round] = scores_class[\"accuracy\"]\n",
    "                results[\"scores\"][\"test_by_class\"][\"f1s\"][k][server_round] = scores_class[\"f1s\"]\n",
    "                \n",
    "        log(INFO, f\"==>> scores: {scores}\")\n",
    "        \n",
    "        \n",
    "        return test_loss, {\"accuracy\": test_acc, \"f1s\": scores[\"f1s\"], \"FPR\": scores[\"FPR\"], \"FNR\": scores[\"FNR\"]}\n",
    "\n",
    "    return evaluate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics):\n",
    "    # print(f\"==>> weighted_average: {metrics}\")\n",
    "\n",
    "    return metrics\n",
    "    # total_examples = 0\n",
    "    # federated_metrics = {k: 0 for k in metrics[0][1].keys()}\n",
    "    # for num_examples, m in metrics:\n",
    "    #     for k, v in m.items():\n",
    "    #         federated_metrics[k] += num_examples * v\n",
    "    #     total_examples += num_examples\n",
    "    # return {k: v / total_examples for k, v in federated_metrics.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_name = \"baseline\"\n",
    "\n",
    "client_data, test, test_labels, test_by_class, input_dim = read_clients(\n",
    "    folder_path, clients_paths, dataset.label_col, dataset.class_col, dataset.class_num_col, centralities_columns, pca_columns, dataset.drop_columns, dataset.weak_columns, cfg.multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configuration': '2dt - baseline',\n",
       " 'dtime': '20241101-232918',\n",
       " 'multi_class': False,\n",
       " 'learning_rate': 0.0001,\n",
       " 'dataset_name': 'cic_ton_iot_5_percent',\n",
       " 'num_classes': 2,\n",
       " 'labels_names': {0: 'benign', 1: 'attack'},\n",
       " 'input_dim': 38,\n",
       " 'scores': {'server': {},\n",
       "  'clients': {},\n",
       "  'accuracy': {},\n",
       "  'f1s': {},\n",
       "  'test_by_class': {'accuracy': {'xss': {},\n",
       "    'Benign': {},\n",
       "    'injection': {},\n",
       "    'password': {},\n",
       "    'ransomware': {},\n",
       "    'scanning': {},\n",
       "    'mitm': {},\n",
       "    'backdoor': {},\n",
       "    'dos': {},\n",
       "    'ddos': {},\n",
       "    'PortScan': {},\n",
       "    'DoS Hulk': {},\n",
       "    'DoS Slowhttptest': {},\n",
       "    'SSH-Patator': {},\n",
       "    'DoS GoldenEye': {},\n",
       "    'DoS slowloris': {},\n",
       "    'FTP-Patator': {},\n",
       "    'Bot': {},\n",
       "    'bruteforce': {}},\n",
       "   'f1s': {'xss': {},\n",
       "    'Benign': {},\n",
       "    'injection': {},\n",
       "    'password': {},\n",
       "    'ransomware': {},\n",
       "    'scanning': {},\n",
       "    'mitm': {},\n",
       "    'backdoor': {},\n",
       "    'dos': {},\n",
       "    'ddos': {},\n",
       "    'PortScan': {},\n",
       "    'DoS Hulk': {},\n",
       "    'DoS Slowhttptest': {},\n",
       "    'SSH-Patator': {},\n",
       "    'DoS GoldenEye': {},\n",
       "    'DoS slowloris': {},\n",
       "    'FTP-Patator': {},\n",
       "    'Bot': {},\n",
       "    'bruteforce': {}},\n",
       "   'length': 8}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}  # a dictionary that will contain all the options and results of models\n",
    "# add all options to the results dictionary, to know what options selected for obtained results\n",
    "results[\"configuration\"] = \"2dt - baseline\"\n",
    "results[\"dtime\"] = dtime\n",
    "results[\"multi_class\"] = cfg.multi_class\n",
    "results[\"learning_rate\"] = learning_rate\n",
    "results[\"dataset_name\"] = dataset.name\n",
    "results[\"num_classes\"] = num_classes\n",
    "results[\"labels_names\"] = labels_names\n",
    "results[\"input_dim\"] = input_dim\n",
    "\n",
    "results[\"scores\"] = {}\n",
    "results[\"scores\"][\"server\"] = {}\n",
    "results[\"scores\"][\"clients\"] = {}\n",
    "results[\"scores\"][\"accuracy\"] = {}\n",
    "results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "if not cfg.multi_class:\n",
    "    results[\"scores\"][\"test_by_class\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "    for k in test_by_class.keys():\n",
    "        results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "        \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "    min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "    fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "    min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "    min_available_clients=len(client_data),  # total clients in the simulation\n",
    "    # fit_metrics_aggregation_fn = weighted_average,\n",
    "    # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "    on_fit_config_fn=get_on_fit_config(\n",
    "        cfg.config_fit\n",
    "    ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "    evaluate_fn=get_evaluate_fn(test, test_labels, input_dim, simulation_name, results, test_by_class),\n",
    ")  # a function to run on the server side to evaluate the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-11-01 23:29:23,012 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "2024-11-01 23:29:40,143\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "INFO flwr 2024-11-01 23:29:48,567 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 253548134.0, 'memory': 507096270.0, 'node:127.0.0.1': 1.0, 'node:__internal_head__': 1.0, 'CPU': 8.0}\n",
      "INFO flwr 2024-11-01 23:29:48,569 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
      "INFO flwr 2024-11-01 23:29:48,572 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
      "INFO flwr 2024-11-01 23:29:48,947 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
      "INFO flwr 2024-11-01 23:29:48,955 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-11-01 23:29:48,957 | server.py:276 | Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[36m(pid=26000)\u001b[0m 2024-11-01 23:29:58.865134: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(pid=26000)\u001b[0m 2024-11-01 23:30:05.376033: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11824)\u001b[0m 2024-11-01 23:30:05.461764: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different nu\n",
      "\u001b[2m\u001b[36m(pid=11824)\u001b[0m merical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10160)\u001b[0m c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10160)\u001b[0m   super().__init__(\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10160)\u001b[0m 2024-11-01 23:30:21.438555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10160)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=10160)\u001b[0m 2024-11-01 23:30:06.857228: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "INFO flwr 2024-11-01 23:30:23,254 | server.py:280 | Received initial parameters from one random client\n",
      "INFO flwr 2024-11-01 23:30:23,266 | server.py:91 | Evaluating initial parameters\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2987 - loss: 1.8855\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:142: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR = TP/(TP+FN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:152: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FNR = FN/(TP+FN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TNR = TN/(TN+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:146: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  PPV = TP/(TP+FP)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:150: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FPR = FP/(FP+TN)\n",
      "c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\src\\deep_learning\\evaluation_metrics.py:154: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FDR = FP/(TP+FP)\n",
      "INFO flwr 2024-11-01 23:30:38,758 | 1935980664.py:68 | ==>> scores: {'accuracy': 0.35443575798776344, 'recall': 0.35443575798776344, 'precision': 0.29930075081141455, 'f1s': 0.30926333078340157, 'FPR': 0.3920060205702818, 'FNR': 0.9074889867841409, 'class_report': '              precision    recall  f1-score   support\\n\\n           0       0.41      0.61      0.49     11959\\n           1       0.19      0.09      0.12     11577\\n\\n    accuracy                           0.35     23536\\n   macro avg       0.30      0.35      0.31     23536\\nweighted avg       0.30      0.35      0.31     23536\\n'}\n",
      "INFO flwr 2024-11-01 23:30:38,884 | server.py:94 | initial parameters (loss, other metrics): 1.7612868547439575, {'accuracy': 0.3544357717037201, 'f1s': 0.30926333078340157, 'FPR': 0.3920060205702818, 'FNR': 0.9074889867841409}\n",
      "INFO flwr 2024-11-01 23:30:38,892 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-11-01 23:30:38,900 | server.py:222 | fit_round 1: strategy sampled 8 clients (out of 8)\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=17388)\u001b[0m c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=17388)\u001b[0m   super().__init__(\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=17388)\u001b[0m 2024-11-01 23:30:41.156628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=17388)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m   super().__init__(\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m 2024-11-01 23:30:47.671919: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instru\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m c\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m t\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m i\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m ons in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=6040)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10300)\u001b[0m 2024-11-01 23:30:53.543165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=14772)\u001b[0m c:\\Users\\mtermos\\Desktop\\Graph-Enhanced-NIDS\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=14772)\u001b[0m   super().__init__(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=10300)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=14772)\u001b[0m 2024-11-01 23:30:59.684102: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=14772)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the a\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=14772)\u001b[0m p\n",
      "\u001b[2m\u001b[36m(DefaultActor pid=14772)\u001b[0m propriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from math import floor\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=generate_client_fn(client_data, simulation_name, input_dim),  # a function that spawns a particular client\n",
    "    # num_clients=cfg.n_clients,  # total number of clients\n",
    "    num_clients=len(client_data),  # total number of clients\n",
    "    config=fl.server.ServerConfig(\n",
    "        num_rounds=cfg.n_rounds\n",
    "        # num_rounds=5\n",
    "    ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "    strategy=strategy,  # our strategy of choice\n",
    "    client_resources={\n",
    "        \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "        # \"num_cpus\": 1,\n",
    "        \"num_gpus\": 0.0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==>> history: {history}\")\n",
    "print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the directories if they don't exist\n",
    "if not os.path.isdir('./results'):\n",
    "    os.mkdir('./results')\n",
    "\n",
    "# creating the directories if they don't exist\n",
    "if not os.path.isdir('./results/{}'.format(dtime)):\n",
    "    os.mkdir('./results/{}'.format(dtime))\n",
    "\n",
    "# if not os.path.isdir('./results/{}'.format(dataset_name)):\n",
    "#     os.mkdir('./results/{}'.format(dataset_name))\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NumpyEncoder, self).default(obj)\n",
    "\n",
    "filename = ('./results/{}/baseline.json'.format(dtime))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ('./results/{}/results_final.json'.format(dtime))\n",
    "outfile = open(filename, 'w')\n",
    "outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n",
    "outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    simulation_name = \"PCA\"\n",
    "    client_data, test, test_labels, test_by_class, input_dim = read_clients(\n",
    "        folder_path, clients_paths, dataset.label_col, dataset.class_col, dataset.class_num_col, centralities_columns, None, dataset.drop_columns, dataset.weak_columns, cfg.multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    results = {}  # a dictionary that will contain all the options and results of models\n",
    "    # add all options to the results dictionary, to know what options selected for obtained results\n",
    "    results[\"configuration\"] = \"2dt - PCA\"\n",
    "    results[\"dtime\"] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    results[\"multi_class\"] = cfg.multi_class\n",
    "    results[\"learning_rate\"] = learning_rate\n",
    "    results[\"dataset_name\"] = dataset.name\n",
    "    results[\"num_classes\"] = num_classes\n",
    "    results[\"labels_names\"] = labels_names\n",
    "    results[\"input_dim\"] = input_dim\n",
    "\n",
    "    results[\"scores\"] = {}\n",
    "    results[\"scores\"][\"server\"] = {}\n",
    "    results[\"scores\"][\"clients\"] = {}\n",
    "    results[\"scores\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "    if not cfg.multi_class:\n",
    "        results[\"scores\"][\"test_by_class\"] = {}\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "        for k in test_by_class.keys():\n",
    "            results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "            results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "            results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "            \n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "        min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "        fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "        min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "        min_available_clients=len(client_data),  # total clients in the simulation\n",
    "        # fit_metrics_aggregation_fn = weighted_average,\n",
    "        # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "        on_fit_config_fn=get_on_fit_config(\n",
    "            cfg.config_fit\n",
    "        ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "        evaluate_fn=get_evaluate_fn(test, test_labels, input_dim, simulation_name, results, test_by_class),\n",
    "    )  # a function to run on the server side to evaluate the global model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    import multiprocessing\n",
    "    from math import floor\n",
    "    history = fl.simulation.start_simulation(\n",
    "        client_fn=generate_client_fn(client_data, simulation_name, input_dim),  # a function that spawns a particular client\n",
    "        # num_clients=cfg.n_clients,  # total number of clients\n",
    "        num_clients=len(client_data),  # total number of clients\n",
    "        config=fl.server.ServerConfig(\n",
    "            num_rounds=cfg.n_rounds\n",
    "            # num_rounds=5\n",
    "        ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "        strategy=strategy,  # our strategy of choice\n",
    "        client_resources={\n",
    "            # \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "            \"num_cpus\": 1,\n",
    "            \"num_gpus\": 0.0,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    print(f\"==>> history: {history}\")\n",
    "    print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    filename = ('./results/{}/pca.json'.format(dtime))\n",
    "    outfile = open(filename, 'w')\n",
    "    outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    filename = ('./results/{}/results_final.json'.format(dtime))\n",
    "    outfile = open(filename, 'w')\n",
    "    outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n",
    "    outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities - DiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    simulation_name = \"digraph\"\n",
    "    client_data, test, test_labels, test_by_class, input_dim = read_clients(\n",
    "        folder_path, clients_paths, dataset.label_col, dataset.class_col, dataset.class_num_col, None, pca_columns, dataset.drop_columns, dataset.weak_columns, cfg.multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    results = {}  # a dictionary that will contain all the options and results of models\n",
    "    # add all options to the results dictionary, to know what options selected for obtained results\n",
    "    results[\"configuration\"] = \"2dt - Centralities - DiGraph\"\n",
    "    results[\"dtime\"] = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    results[\"multi_class\"] = cfg.multi_class\n",
    "    results[\"learning_rate\"] = learning_rate\n",
    "    results[\"dataset_name\"] = dataset.name\n",
    "    results[\"num_classes\"] = num_classes\n",
    "    results[\"labels_names\"] = labels_names\n",
    "    results[\"input_dim\"] = input_dim\n",
    "\n",
    "    results[\"scores\"] = {}\n",
    "    results[\"scores\"][\"server\"] = {}\n",
    "    results[\"scores\"][\"clients\"] = {}\n",
    "    results[\"scores\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "    if not cfg.multi_class:\n",
    "        results[\"scores\"][\"test_by_class\"] = {}\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "        for k in test_by_class.keys():\n",
    "            results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "            results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "            results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "            \n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "        min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "        fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "        min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "        min_available_clients=len(client_data),  # total clients in the simulation\n",
    "        # fit_metrics_aggregation_fn = weighted_average,\n",
    "        # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "        on_fit_config_fn=get_on_fit_config(\n",
    "            cfg.config_fit\n",
    "        ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "        evaluate_fn=get_evaluate_fn(test, test_labels, input_dim, simulation_name, results, test_by_class),\n",
    "    )  # a function to run on the server side to evaluate the global model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    import multiprocessing\n",
    "    from math import floor\n",
    "    history = fl.simulation.start_simulation(\n",
    "        client_fn=generate_client_fn(client_data, simulation_name, input_dim),  # a function that spawns a particular client\n",
    "        # num_clients=cfg.n_clients,  # total number of clients\n",
    "        num_clients=len(client_data),  # total number of clients\n",
    "        config=fl.server.ServerConfig(\n",
    "            num_rounds=cfg.n_rounds\n",
    "            # num_rounds=5\n",
    "        ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "        strategy=strategy,  # our strategy of choice\n",
    "        client_resources={\n",
    "            # \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "            \"num_cpus\": 1,\n",
    "            \"num_gpus\": 0.0,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    print(f\"==>> history: {history}\")\n",
    "    print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    filename = ('./results/{}/digraph.json'.format(dtime))\n",
    "    outfile = open(filename, 'w')\n",
    "    outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if digraph_centralities:\n",
    "    filename = ('./results/{}/results_final.json'.format(dtime))\n",
    "    outfile = open(filename, 'w')\n",
    "    outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n",
    "    outfile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralities - MultiDiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    simulation_name = \"multidigraph\"\n",
    "    client_data, test, test_labels, test_by_class, input_dim = read_clients(\n",
    "        folder_path, clients_paths, dataset.label_col, dataset.class_col, dataset.class_num_col, centralities_columns, pca_columns, dataset.drop_columns, dataset.weak_columns, cfg.multi_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    results = {}  # a dictionary that will contain all the options and results of models\n",
    "    # add all options to the results dictionary, to know what options selected for obtained results\n",
    "    results[\"configuration\"] = \"2dt - Centralities - MultiDiGraph\"\n",
    "    results[\"dtime\"] = dtime\n",
    "    results[\"multi_class\"] = cfg.multi_class\n",
    "    results[\"learning_rate\"] = learning_rate\n",
    "    results[\"dataset_name\"] = dataset.name\n",
    "    results[\"num_classes\"] = num_classes\n",
    "    results[\"labels_names\"] = labels_names\n",
    "    results[\"input_dim\"] = input_dim\n",
    "\n",
    "    results[\"scores\"] = {}\n",
    "    results[\"scores\"][\"server\"] = {}\n",
    "    results[\"scores\"][\"clients\"] = {}\n",
    "    results[\"scores\"][\"accuracy\"] = {}\n",
    "    results[\"scores\"][\"f1s\"] = {}\n",
    "\n",
    "    if not cfg.multi_class:\n",
    "        results[\"scores\"][\"test_by_class\"] = {}\n",
    "        results[\"scores\"][\"test_by_class\"][\"accuracy\"] = {}\n",
    "        results[\"scores\"][\"test_by_class\"][\"f1s\"] = {}\n",
    "        for k in test_by_class.keys():\n",
    "            results[\"scores\"][\"test_by_class\"][\"length\"] = len(test_by_class[k][0])\n",
    "            results[\"scores\"][\"test_by_class\"][\"accuracy\"][k] = {}   \n",
    "            results[\"scores\"][\"test_by_class\"][\"f1s\"][k] = {}    \n",
    "            \n",
    "    results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # in simulation, since all clients are available at all times, we can just use `min_fit_clients` to control exactly how many clients we want to involve during fit\n",
    "        min_fit_clients=len(client_data),  # number of clients to sample for fit()\n",
    "        fraction_evaluate=0.0,  # similar to fraction_fit, we don't need to use this argument.\n",
    "        min_evaluate_clients=0,  # number of clients to sample for evaluate()\n",
    "        min_available_clients=len(client_data),  # total clients in the simulation\n",
    "        # fit_metrics_aggregation_fn = weighted_average,\n",
    "        # evaluate_metrics_aggregation_fn = weighted_average,\n",
    "        on_fit_config_fn=get_on_fit_config(\n",
    "            cfg.config_fit\n",
    "        ),  # a function to execute to obtain the configuration to send to the clients during fit()\n",
    "        evaluate_fn=get_evaluate_fn(test, test_labels, input_dim, simulation_name, results, test_by_class),\n",
    "    )  # a function to run on the server side to evaluate the global model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    history = fl.simulation.start_simulation(\n",
    "        client_fn=generate_client_fn(client_data, simulation_name, input_dim),  # a function that spawns a particular client\n",
    "        # num_clients=cfg.n_clients,  # total number of clients\n",
    "        num_clients=len(client_data),  # total number of clients\n",
    "        config=fl.server.ServerConfig(\n",
    "            num_rounds=cfg.n_rounds\n",
    "            # num_rounds=5\n",
    "        ),  # minimal config for the server loop telling the number of rounds in FL\n",
    "        strategy=strategy,  # our strategy of choice\n",
    "        client_resources={\n",
    "            # \"num_cpus\": floor(multiprocessing.cpu_count() / len(client_data)),\n",
    "            \"num_cpus\": 1,\n",
    "            \"num_gpus\": 0.0,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    print(f\"==>> history: {history}\")\n",
    "    print(f\"==>> end of history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    filename = ('./results/{}/multidigraph.json'.format(dtime))\n",
    "    outfile = open(filename, 'w')\n",
    "    outfile.writelines(json.dumps(results, cls=NumpyEncoder))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_graph_centralities:\n",
    "    filename = ('./results/{}/results_final.json'.format(dtime))\n",
    "    outfile = open(filename, 'w')\n",
    "    outfile.writelines(json.dumps(results_final, cls=NumpyEncoder))\n",
    "    outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
